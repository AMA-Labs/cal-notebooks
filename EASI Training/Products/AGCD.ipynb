{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian Gridded Climate Data <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (imports, dask, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Create a mask (quality layer)](#Create-a-mask)\n",
    "- [Define scaling (scale, offset)](#Define-scaling)\n",
    "- [Select a data layer (process)](#Select-a-data-layer)\n",
    "- [Visualise](#Visualise)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Australian Gridded Climate Data collection are gridded surface meteorology layers for Australia produced by the Bureau of Meteorology (BoM). The rainfall, temperature and vapour pressure data come from the BoM's network of rain gauges and weather stations. Observation station data are interpolated to a spatial resolution of 0.05 degrees latitude and longitude (~5 km x 5km). Data are unprojected, in geographic decimal degrees, referenced to GDA94 (equivalent to WGS84 for all practical purposes). The solar irradiance data are derived from geostationary meteorological satellite imagery, and similarly gridded.\n",
    "\n",
    "Rainfall data are available for 1900 to present, temperatures from 1911 to present, vapour pressure from 1950 to present, and solar irradiance from 1990 to present. Most parameters have \"day\" and \"month\" layers and some have \"RMSE\" layers as well.\n",
    "\n",
    "Key references for Bureau of Meteorology AWAP data are Jones et al. (2009) and Grant et al. (2008) and the information at http://www.bom.gov.au/climate/maps/.\n",
    "\n",
    "#### Recalibrated rainfall\n",
    "\n",
    "`agdc_rain_recal_day`: This product is generated by rescaling daily rainfall at the end of each month so that the sum of daily rainfalls matches the monthly reanalyses. The discrepancy between the sums of original daily rainfalls and the end-of-month reanalyses is due to differences in the interpolation methods applied to daily and monthly rainfall because of their different spatial structures. Interpolation failures in the (uncalibrated) daily data occur in sparsely gauged areas of the continent such as the Central and Western Deserts. These are removed in the recalibrated rainfall product and replaced with missing data values.\n",
    "\n",
    "_This product is recommended for longer-term analyses that would benefit from consistency between daily and monthly values._\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "Individual data files can be manually downloaded, and verified, at http://www.bom.gov.au/climate/maps/.\n",
    "\n",
    "CSIRO has a license agreement with BoM to receive the data and produce value-added products.\n",
    "\n",
    "Key references:\n",
    "\n",
    "- Jones DA, Wang W, Fawcett R (2009), High-quality spatial climate data-sets \n",
    "  for Australia. Australian Meteorological and Oceanographic Journal 58:233-248\n",
    "- Grant I, D Jones, W Wang, R Fawcett, D Barratt (2008), Meteorological and\n",
    "  remotely sensed datasets for hydrological modelling: A contribution to the\n",
    "  Australian Water Availability Project. Proceedings of the Catchment-scale\n",
    "  Hydrological Modelling & Data Assimilation (CAHMDA-3) International Workshop\n",
    "  on Hydrological Prediction: Modelling, Observation and Data Assimilation,\n",
    "  Melbourne, January 9-11 2008.\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "| Task | Summary |\n",
    "|------|---------|\n",
    "| Source | Collate sources and versions of the full set of variables for all available time (CSIRO internal) |\n",
    "| Download | Daily downloads from BoM FTP (CSIRO internal) |\n",
    "| Preprocess | |\n",
    "| Format | COG |\n",
    "| Location | s3://landscapes-easi-shared/agcd/ (not public) |\n",
    "\n",
    "Contacts: Rob Bridgart, Matt Paget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('../../scripts'))\n",
    "import notebook_utils\n",
    "\n",
    "# Hide ShapelyDeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.+Shapely 2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, client = notebook_utils.initialize_dask(workers=(1,2), use_gateway=False)\n",
    "display(cluster)\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "\n",
    "Change any of the parameters in the query object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product:\n",
    "- https://explorer.csiro.easi-eo.solutions  + /product (when available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area name\n",
    "min_longitude, max_longitude = (110,154)\n",
    "min_latitude, max_latitude = (-45,-10)\n",
    "min_date = '2021-01-01'\n",
    "max_date = '2021-12-31'\n",
    "\n",
    "query = {\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'latitude': 2048, 'longitude': 2048},  # Dask chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('agcd_(\\w+)_([a-z]+)$')\n",
    "\n",
    "def load_awap_product(product, query):\n",
    "\n",
    "    # Load data\n",
    "    data = dc.load(product=product, **query)\n",
    "\n",
    "    # notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "    # display(data)\n",
    "\n",
    "    # Calculate valid (not nodata) masks for each layer\n",
    "    valid_mask = masking.valid_data_mask(data)\n",
    "    \n",
    "    # Apply valid mask and good pixel mask\n",
    "    m = p.match(product)\n",
    "    layer_name = m.group(1)\n",
    "    layer = data[[layer_name]].where(valid_mask[layer_name])\n",
    "    layer = layer.persist()\n",
    "    \n",
    "    return layer, layer_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements for the selected product\n",
    "measurements = dc.list_measurements().loc[query['product']]\n",
    "measurements\n",
    "# # The AGDC products do not have flag_definition measurements; just missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = {\n",
    "    'agcd_rain_recal_day': (0,400),\n",
    "    'agcd_rain_rmse_day': (0,100),\n",
    "    'agcd_rain_rmse_month': (0,200),\n",
    "    'agcd_rain_total_day': (0,400),\n",
    "    'agcd_rain_total_month': (0,800),\n",
    "    'agcd_solar_exposure_day': (0,40),\n",
    "    'agcd_solar_exposure_month': (0,40),\n",
    "    'agcd_tmax_mean_day': (0,45),\n",
    "    'agcd_tmax_mean_month': (0,45),\n",
    "    'agcd_tmax_rmse_day': (0,10),\n",
    "    'agcd_tmax_rmse_month': (0,10),\n",
    "    'agcd_tmin_mean_day': (0,30),\n",
    "    'agcd_tmin_mean_month': (0,30),\n",
    "    'agcd_tmin_rmse_day': (0,10),\n",
    "    'agcd_tmin_rmse_month': (0,10),\n",
    "    'agcd_vp09_mean_day': (0,36),\n",
    "    'agcd_vp09_mean_month': (0,36),\n",
    "    'agcd_vp15_mean_day': (0,36),\n",
    "    'agcd_vp15_mean_month': (0,36),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def awap_plot(layer, product, layer_name):\n",
    "\n",
    "    # Generate a plot\n",
    "\n",
    "    options = {\n",
    "        'title': f'{product}: {layer_name}',\n",
    "        'width': 800,\n",
    "        'height': 450,\n",
    "        'aspect': 'equal',\n",
    "        'cmap': cc.rainbow,\n",
    "        'clim': clim[product],\n",
    "        'colorbar': True,\n",
    "        'tools': ['hover'],\n",
    "    }\n",
    "\n",
    "    # Set the Dataset CRS\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "    # Native data and coastline overlay:\n",
    "    # - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "    # TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "    layer_plot = layer.hvplot.image(\n",
    "        x = 'longitude', y = 'latitude',                        # Dataset x,y dimension names\n",
    "        rasterize = True,                        # Use Datashader\n",
    "        aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "        precompute = True,                       # Datashader precomputes what it can\n",
    "        crs = plot_crs,                        # Dataset crs\n",
    "        projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "        coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    "    ).options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "    # display(layer_plot)\n",
    "    # Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "    fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in awap_clim.keys():\n",
    "    try:\n",
    "        layer, layer_name = load_awap_product(product)\n",
    "        display(layer)\n",
    "        awap_plot(layer, product, layer_name)\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
