{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9790a2",
   "metadata": {},
   "source": [
    "# Copernicus Digital Elevation Model <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "_Work in progress_\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31686be3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Copernicus DEM is a Digital Surface Model (DSM) which represents the surface of the Earth including buildings, infrastructure and vegetation.\n",
    " \n",
    "We have found that there are obviously significant improvements compared to the widely used SRTM 30m DEM: better quality (in terms of both horizontal and vertical accuracies) and newer acquisitions (SRTM in 2000 vs TanDEM-X in 2010-2015 or so). We recommend the Copernicus GLO-30 DEM for your research work if applicable [Zheng-Shu Zhou, CSIRO].\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "https://registry.opendata.aws/copernicus-dem/\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "| Task | Summary |\n",
    "|------|---------|\n",
    "| Source | s3://copernicus-dem-30m |\n",
    "| Download | Compute tile set for given geojson |\n",
    "| Preprocess | |\n",
    "| Format | |\n",
    "| Prepare | |\n",
    "| TODO | Update preparation code from first draft|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1d781",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.0.122.92:33945\")\n",
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6618e13",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('~/hub-notebooks/scripts'))\n",
    "import notebook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9038f4",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1dbc00",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "\n",
    "Change any of the parameters in the query object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product:\n",
    "- https://explorer.csiro.easi-eo.solutions  + /product (when available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area name\n",
    "min_longitude, max_longitude = (136,154)\n",
    "min_latitude, max_latitude = (-39,-28)\n",
    "min_date = '31-12-2015'\n",
    "max_date = '31-12-2015'\n",
    "product = 'copernicus_dem_30'\n",
    "\n",
    "query = {\n",
    "    'product': product,                     # Product name\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "}\n",
    "\n",
    "# Most common CRS\n",
    "native_crs = notebook_utils.mostcommon_crs(dc, query)\n",
    "display(native_crs)\n",
    "\n",
    "query.update({\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (-1/3600., 1/3600.),                # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'latitude': 4096, 'longitude': 4096},  # Dask chunks\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Some products require AWS S3 credentials to supplied\n",
    "\n",
    "# S3 credentials - required for s2_l2a\n",
    "# configure_s3_access(aws_unsigned=True,requester_pays=False,client=client)\n",
    "# print(\"Configured s3 requester pays data access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2526cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011dfd5",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125428d",
   "metadata": {},
   "source": [
    "## Quality layer\n",
    "\n",
    "No quality layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8525f",
   "metadata": {},
   "source": [
    "## Masking and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'elevation'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data[[layer_name]].where(data[layer_name] > 0)\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa06ccc",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 800,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': plt.cm.terrain,\n",
    "    'clim': (0, 2200),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'longitude', y = 'latitude',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                        # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b243d68",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d848910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
