{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Precipitation Measurement <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Global Precipitation Measurement (GPM) mission is an international network of satellites that provide next-generation global observations of rain and snow (https://gpm.nasa.gov/missions/GPM).\n",
    "\n",
    "The Integrated Multi-satellitE Retrievals for GPM (IMERG) is the unified U.S. algorithm that provides the multi-satellite precipitation product for the U.S. GPM team. The precipitation estimates from the various precipitation-relevant satellite passive microwave (PMW) sensors comprising the GPM constellation are computed using the 2017 version of the Goddard Profiling Algorithm (GPROF2017), then gridded, intercalibrated to the GPM Combined Ku Radar-Radiometer Algorithm (CORRA) product, and merged into half-hourly 0.1°x0.1° (roughly 10x10 km) fields (https://disc.gsfc.nasa.gov/datasets/GPM_3IMERGM_06/summary).\n",
    "\n",
    "\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "| Product name | Long name | Notes |\n",
    "|--|--|--|\n",
    "| gpm_3imerg_month | GPM IMERG Final Precipitation L3 1 month 0.1 degree x 0.1 degree V06 (GPM_3IMERGM) | \"Final\" is available ~3.5 months after the observation month |\n",
    "\n",
    "- [Algorithm Theoretical Basis Document (ATBD), Version 06, 13 March 2019](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_ATBD_V06.pdf)\n",
    "- [Integrated Multi-satellitE Retrievals for GPM (IMERG) Technical Documentation, 6 October 2020](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_doc.06.pdf)\n",
    "- [IMERG V06 Quality Index, 15 March 2019](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERGV06_QI.pdf)\n",
    "- [README Document for the GPM Data, 03/12/2017](https://gpm1.gesdisc.eosdis.nasa.gov/data/GPM_L3/doc/README.GPM.pdf)\n",
    "- [V06 IMERG Release Notes, 6 October 2020](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_V06_release_notes.pdf)\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "| Task | Summary |\n",
    "|------|---------|\n",
    "| Source | https://gpm1.gesdisc.eosdis.nasa.gov/data/GPM_L3/GPM_3IMERGM.06 |\n",
    "| Download | Manual |\n",
    "| Preprocess | Extract HDF5 variables |\n",
    "| Format | COG |\n",
    "| Prepare | EO3 |\n",
    "| TODO | |\n",
    "\n",
    "| Measurement name | Description |\n",
    "|--|--|\n",
    "| precipitation | Merged satellite-gauge precipitation estimate (recommended for general use) |\n",
    "| random_error | Random error for merged satellite-gauge precipitation. Computed as in Huffman (1997) |\n",
    "| gauge_relative_weighting | Weighting of gauge precipitation relative to the multi-satellite precipitation |\n",
    "| probability_liquid_precipitation | Accumulation-weighted probability of liquid precipitation phase. Essentially the fraction of the monthly accumulation that fell as liquid |\n",
    "| precipitation_quality_index | Quality Index for precipitation field. Equivalent number of gauges per 2.5° box<br>The approximate number of gauges required to produce the estimated random error, given the estimated precipitation<br>0-2 = Equivalent to the gauge coverage in regions such as central Africa, where the lack of data in a gauge-only analysis a critical problem<br>2-4 = Mid-range has enough gauge data to ensure reasonable bias adjustment, but still require interpolation to fill in gaps several grid boxes wide between stations more or less routinely<br>4+ = Developed areas with good-to-excellent gauge networks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.0.79.184:37537\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('~/hub-notebooks/scripts'))\n",
    "import notebook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development products:\n",
    "#  - This is a development ODC database while we test and demo this product.\n",
    "# CONF = \"\"\"\n",
    "# [datacube]\n",
    "# db_hostname: v2-db-easihub-csiro-eks.cluster-ro-cvaedcg0qvwd.ap-southeast-2.rds.amazonaws.com\n",
    "# db_database: user_dev_odc\n",
    "# db_username: user\n",
    "# db_password: secretpassword\n",
    "# \"\"\"\n",
    "# from datacube.config import read_config, LocalConfig\n",
    "# dc = datacube.Datacube(config=LocalConfig(read_config(CONF)), env='datacube')\n",
    "\n",
    "# dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "\n",
    "Change any of the parameters in the query object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product:\n",
    "- https://explorer.csiro.easi-eo.solutions  + /product (when available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area name\n",
    "min_longitude, max_longitude = (-180, 180)\n",
    "min_latitude, max_latitude = (-90, 90)\n",
    "min_date = '2000-06-01'\n",
    "max_date = '2021-12-31'\n",
    "product = 'gpm_3imerg_month'\n",
    "\n",
    "native_crs = 'epsg:4326'\n",
    "\n",
    "query = {\n",
    "    'product': product,                     # Product name\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (-0.1, 0.1),             # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'latitude': 2048, 'longitude': 2048},  # Dask chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dc = datacube.Datacube()\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make flags image\n",
    "flag_name = 'precipitation_quality_index'\n",
    "flag_data = data[[flag_name]].where(valid_mask[flag_name]).persist()   # Dataset\n",
    "display(flag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These options manipulate the color map and colorbar to show the categories for this product\n",
    "options = {\n",
    "    'title': f'Flag data for: {query[\"product\"]} ({flag_name})',\n",
    "    'cmap': cc.rainbow,\n",
    "    'colorbar': True,\n",
    "    'width': 800,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "quality_plot = flag_data.hvplot.image(\n",
    "    x = 'longitude', y = 'latitude',         # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mode(),          # Datashader selects mode value, requires 'hv.Image'\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset CRS\n",
    "    projection = ccrs.PlateCarree(),         # Output Projection (ccrs.PlateCarree() when coastline=True)\n",
    "    coastline = '10m',                       # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist()\n",
    "\n",
    "# display(quality_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(quality_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask layer\n",
    "\n",
    "# precipitation_quality_index\n",
    "# 0-2 = Equivalent to the gauge coverage in regions such as central Africa, where the lack of data in a gauge-only analysis a critical problem\n",
    "# 2-4 = Mid-range has enough gauge data to ensure reasonable bias adjustment, but still require interpolation to fill in gaps several grid boxes wide between stations more or less routinely\n",
    "# 4+ = Developed areas with good-to-excellent gauge networks\n",
    "\n",
    "flag_name = 'precipitation_quality_index'\n",
    "good_pixel_mask = data[flag_name] > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling\n",
    "\n",
    "# No scaling\n",
    "# scale = 1.\n",
    "# offset = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'precipitation'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data[[layer_name]].where(valid_mask[layer_name] & good_pixel_mask)\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a plot\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 800,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': cc.rainbow,\n",
    "    'clim': (0, 2),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'longitude', y = 'latitude',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                        # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
