{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-2 (global) <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Optional: Reproject](#Optional:-Reproject)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sentinel-2 is an Earth observation mission from the EU Copernicus Programme that systematically acquires optical imagery at high spatial resolution (up to 10 m for some bands). The mission is a constellation of two identical satellites in the same orbit, 180Â° apart for optimal coverage and data delivery. Together, they cover all Earth's land surfaces, large islands, inland and coastal waters every 3-5 days.\n",
    "\n",
    "Sentinel-2A was launched on 23 June 2015 and Sentinel-2B followed on 7 March 2017.\n",
    "Both of the Sentinel-2 satellites carry a wide swath high-resolution multispectral imager with 13 spectral bands.\n",
    "For more information on the Sentinel-2 platforms and applications see the [European Space Agency website](http://www.esa.int/Applications/Observing_the_Earth/Copernicus/Overview4).\n",
    "\n",
    "_Adapted from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/DEA_datasets/Sentinel_2.ipynb_\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "EASI provides at least four Sentinel-2 products from three sources of data. These represent Analysis Ready Data (ARD) products corrected to surface reflectance.\n",
    "\n",
    "We describe in this notebook the products that can be used in a global context. That is, products processed with globaly applicable algorithms.\n",
    "\n",
    "| Name | Product | Information |\n",
    "|------|---------|-------------|\n",
    "| CopHub S2 Sen2cor | `cophub_s2_sr_sen2cor` | - Download S2 L2A sen2cor from EC Copernicus Data Hub (\"CopHub\"). Process to COG with the same structure as for `s2_l2a`. [More information below](#EC-Copernicus-Data-Hub)<br>- Use for global AOIs where custom preprocessing is required or analyses will benefit from a local data source |\n",
    "| Sentinel-2 COGs | `s2_l2a` | - Direct indexing from Sentinel-2 Cloud-Optimized GeoTIFFs (uses the same S2 L2A Sen2cor source data as for `cophub_s2_sr_sen2cor`). [More information below](#Sentinel-2-Cloud-Optimized-GeoTIFFs)<br>- Use for global AOIs where Sen2cor surface correction is required |\n",
    "\n",
    "See the companion notebook, \"Sentinel-2 (Australia)\" for an introduction to the Geoscience Australia products:\n",
    "\n",
    "***---Split---***\n",
    "\n",
    "| Name | Product | Information |\n",
    "|------|---------|-------------|\n",
    "| GA S2 NBAR | `ga_s2a_ard_nbar_granule`<br>`ga_s2b_ard_nbar_granule` | - Geoscience Australia S2 NBAR and NBART surface corrected for Australia. [More information below](#Geoscience-Australia-NBAR-corrected-for-Australia)<br>- Use for Australian AOIs |\n",
    "| GA S2 NRT | `s2a_nrt_granule`<br>`s2b_nrt_granule` | - Geoscience Australia S2 Near-Real-Time NBAR and NBART surface corrected for Australia. [More information below](#Geoscience-Australia-NBAR-corrected-for-Australia)<br>- Use for Australian AOIs where analyses benefit from near real time data |\n",
    "| | `s2(a,b)_nrt_granule` | Not currently indexed by EASI. They are currently available on NCI only |\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "| Task | `cophub_s2_sr_sen2cor` | `s2_l2a` |\n",
    "|------|------------------------|----------|\n",
    "| Source | https://scihub.copernicus.eu | https://registry.opendata.aws/sentinel-2-l2a-cogs |\n",
    "| Download | Y | Index in place |\n",
    "| Preprocess | Select bands by resolution | N/A |\n",
    "| Format | Convert JP2 to COG | N/A |\n",
    "| Prepare | Y | stac-to-dc |\n",
    "| TODO | Update \"band_0X\" aliases<br>Capitalise SLC flag #9<br>Extend to L1+Atcor | |\n",
    "\n",
    "***---Split---***\n",
    "\n",
    "| Task | `ga_s2a_ard_nbar_granule` and `ga_s2b_ard_nbar_granule` |\n",
    "|------|---------------------------------------------------------|\n",
    "| Source | s3://dea-public-data/L2/sentinel-2-nbar/S2MSIARD_NBAR |\n",
    "| Download | Index in place |\n",
    "| Preprocess | N/A |\n",
    "| Format | N/A |\n",
    "| Prepare | s3-to-dc |\n",
    "| TODO | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.0.90.144:44565\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('~/hub-notebooks/scripts'))\n",
    "import notebook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "\n",
    "Change any of the parameters in the `query` object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product:\n",
    "- https://explorer.csiro.easi-eo.solutions/cophub_s2_sr_sen2cor\n",
    "- https://explorer.csiro.easi-eo.solutions/s2_l2a\n",
    "\n",
    "***---Split---***\n",
    "\n",
    "- https://explorer.csiro.easi-eo.solutions/ga_s2a_ard_nbar_granule and [ga_s2b_ard_nbar_granule](https://explorer.csiro.easi-eo.solutions/ga_s2b_ard_nbar_granule)\n",
    "- https://explorer.csiro.easi-eo.solutions/s2a_nrt_granule and [s2b_nrt_granule](https://explorer.csiro.easi-eo.solutions/s2b_nrt_granule) \n",
    "\n",
    "Sentinel-2 datasets are stored with different coordinate reference systems (CRS), corresponding to multiple UTM zones used for S2 L1B tiling. S2 measurement bands also have different resolutions (10 m, 20 m and 60 m). As such S2 queries need to include the following two query parameters:\n",
    "\n",
    "* `output_crs` - This sets a consistent CRS that all Sentinel-2 data will be reprojected to, irrespective of the UTM zone the individual image is stored in.\n",
    "* `resolution` - This sets the resolution that all Sentinel-2 images will be resampled to. \n",
    "\n",
    "Use `mostcommon_crs()` to select a CRS. Adapted from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indonesia\n",
    "min_longitude, max_longitude = (117.30, 120)\n",
    "min_latitude, max_latitude = (-9.00, -7.50)\n",
    "min_date = '2020-01-01'\n",
    "max_date = '2020-06-01'\n",
    "product = 'cophub_s2_sr_sen2cor'\n",
    "\n",
    "query = {\n",
    "    'product': product,                     # Product name\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "}\n",
    "\n",
    "# Most common CRS\n",
    "native_crs = notebook_utils.mostcommon_crs(dc, query)\n",
    "\n",
    "query.update({\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (-20, 20),                # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'x': 2048, 'y': 2048},  # Dask chunks\n",
    "})\n",
    "\n",
    "# ***---Split---***\n",
    "\n",
    "# Lake Hume for ga_s2a_ard_nbar_granule and s2a_nrt_granule\n",
    "# min_longitude, max_longitude = (146.92, 147.25)\n",
    "# min_latitude, max_latitude = (-36.25, -35.92)\n",
    "# min_date = '2019-01-01'\n",
    "# max_date = '2019-12-31'\n",
    "# products = ['ga_s2a_ard_nbar_granule', 'ga_s2b_ard_nbar_granule']\n",
    "\n",
    "# native_crs = ccrs.AlbersEqualArea()  # Target projection CRS\n",
    "\n",
    "# query = {\n",
    "#     'product': product,                          # Product name\n",
    "#     'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "#     'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "#     'time': (min_date, max_date),           # Any parsable date strings\n",
    "#     'output_crs': native_crs,              # EPSG code\n",
    "#     'resolution': (-20, 20),                # Target resolution\n",
    "#     'group_by': 'solar_day',                # Scene ordering\n",
    "#     'dask_chunks': {'x': 2048, 'y': 2048},  # Dask chunks\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Some products require AWS S3 credentials to supplied\n",
    "\n",
    "# S3 credentials - required for s2_l2a\n",
    "# configure_s3_access(aws_unsigned=True,requester_pays=False,client=client)\n",
    "# print('Configured s3 requester pays data access')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions.\n",
    "\n",
    "See [Appendix](#Appendix) for a Table of Sentinel-2 ARD bands and corresponding product measurement and alias names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make L2_FLAGS image\n",
    "flag_name = 'quality'\n",
    "flag_data = data[[flag_name]].where(valid_mask[flag_name]).persist()   # Dataset\n",
    "display(flag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make SCL image\n",
    "# https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm\n",
    "# https://www.sentinel-hub.com/faq/how-get-s2a-scene-classification-sentinel-2/\n",
    "\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "\n",
    "color_def = [\n",
    "    (0,  '#000000', 'No data'),   # black\n",
    "    (1,  '#ff0004', 'Saturated or defective'),   # red\n",
    "    (2,  '#868686', 'Dark features or shadows'),   # gray\n",
    "    (3,  '#774c0b', 'Cloud shadows'),   # brown\n",
    "    (4,  '#10d32d', 'Vegetation'),   # green\n",
    "    (5,  '#ffff53', 'Not vegetated'),   # yellow\n",
    "    (6,  '#0000ff', 'Water'),   # blue\n",
    "    (7,  '#818181', 'Unclassified'),   # medium gray\n",
    "    (8,  '#c0c0c0', 'Cloud medium probability'),   # light gray\n",
    "    (9,  '#f2f2f2', 'cloud high probability'),   # very light gray\n",
    "    (10, '#bbc5ec', 'Thin cirrus'),   # light blue/purple\n",
    "    (11, '#53fff9', 'Snow or ice'),   # cyan\n",
    "]\n",
    "color_val = [x[0] for x in color_def]\n",
    "color_hex = [x[1] for x in color_def]\n",
    "color_txt = [f'{x[0]:2d}: {x[2]}' for x in color_def]\n",
    "color_lim = (min(color_val), max(color_val) + 1)\n",
    "bin_edges = color_val + [max(color_val) + 1]\n",
    "bin_range = (color_val[0] + 0.5, color_val[-1] + 0.5)  # No idea why (0.5,11.5) works and (0,11) or (0,12) do not\n",
    "\n",
    "# These options manipulate the color map and colorbar to show the categories for this product\n",
    "options = {\n",
    "    'title': f'Flag data for: {query[\"product\"]} ({flag_name})',\n",
    "    'cmap': color_hex,\n",
    "    'clim': color_lim,\n",
    "    'color_levels': bin_edges,\n",
    "    'colorbar': True,\n",
    "    'width': 800,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'tools': ['hover'],\n",
    "    'colorbar_opts': {\n",
    "        'major_label_overrides': dict(zip(color_val, color_txt)),\n",
    "        'major_label_text_align': 'left',\n",
    "        'ticker': FixedTicker(ticks=color_val),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "quality_plot = flag_data.hvplot.image(\n",
    "    x = 'x', y = 'y',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mode(),          # Datashader selects mode value, requires 'hv.Image'\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Datset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (ccrs.PlateCarree() when coastline=True)\n",
    "    coastline = '10m',                       # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = bin_range)\n",
    "\n",
    "# display(quality_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(quality_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)\n",
    "\n",
    "# Indonesia, Saleh Bay: every 5th day from 2020-01-05 to 2020-01-25\n",
    "# Eyeballing with Google Maps suggests the S2 is correct and the coastline is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Mask layer\n",
    "\n",
    "good_pixel_flags = [color_def[i][2] for i in [4, 5, 6]]\n",
    "\n",
    "good_pixel_mask = enum_to_bool(data[flag_name], good_pixel_flags)  # -> DataArray\n",
    "display(good_pixel_mask)  # Type: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling\n",
    "\n",
    "# http://step.esa.int/thirdparties/sen2cor/2.8.0/docs/S2-PDGS-MPC-L2A-IODD-V2.8.pdf\n",
    "# 1 / 10.000: i.e.: Digital Numbers 0 : 10.000, representing radiometric\n",
    "# reflectance values from 0.0 to 1.0\n",
    "\n",
    "# Cophub sen2cor S2 products\n",
    "scale = 0.0001  # div 10000\n",
    "offset = 0.\n",
    "\n",
    "# ***---Split---***\n",
    "# GA S2 products\n",
    "# scale = 0.0001  # div 10000\n",
    "# offset = 0.\n",
    "# flag_name = 'fmask'\n",
    "# categories =['valid', 'snow', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'nir'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data[[layer_name]].where(valid_mask[layer_name] & good_pixel_mask) * scale + offset\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a plot\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 800,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': cc.rainbow,\n",
    "    'clim': (0, 1),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'x', y = 'y',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                        # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)\n",
    "\n",
    "# Good image of Sarawak: 2020-01-27 0555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Reproject\n",
    "\n",
    "Use xr_reproject to reproject to UTM data to a new project, e.g. to align with other datasets\n",
    "\n",
    "See [dea-notebooks/Frequently_used_code/Reprojecting_data.ipynb](#../../../dea-notebooks/Frequently_used_code/Reprojecting_data.ipynb) for additional examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example uses the query bounding box and epsg:4326  as the target\n",
    "\n",
    "target_crs = 'epsg:4326'\n",
    "target_res = (0.0002, 0.0002)   # approx. 20 m\n",
    "\n",
    "target = GeoBox.from_geopolygon(box(min_longitude, min_latitude, max_longitude, max_latitude, target_crs), target_res)\n",
    "layer_geo = xr_reproject(layer, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Dataset CRS\n",
    "plot_crs = target_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "    \n",
    "layer_plot = layer_geo.hvplot.image(\n",
    "    x = 'longitude', y = 'latitude',         # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Sentinel-2 ARD bands and corresponding product measurement and _alias_ names. This table has been created manually. \n",
    "\n",
    "|Band|Resolution (m)|cophub_s2_sr_sen2cor|s2_l2a|ga_s2a_ard_nbar_granule|\n",
    "|----|----------|--------------------|------|-----------------------|\n",
    "| B1 | 60 | coastal_aerosol<br>_B01 / B01_60m / band_1_ | B01<br>_band_01 / coastal_aerosol_ | nbar_coastal_aerosol<br>_nbar_band_01 / nbar_B01 / nbar_Band1_ |\n",
    "| B2 | 10 | blue<br>_B02 / B02_10m / band_2_ | B02<br>_band_02 / blue_ | nbar_blue<br>_nbar_band_02 / nbar_B02 / nbar_Band2_ |\n",
    "| B3 | 10 | green<br>_B03 / B03_10m / band_3_ | B03<br>_band_03 / green_ | nbar_green<br>_nbar_band_03 / nbar_B03 / nbar_Band3_ |\n",
    "| B4 | 10 | red<br>_B04 / B04_10m / band_4_ | B04<br>_band_04 / red_ | nbar_red<br>_nbar_band_04 / nbar_B04 / nbar_Band4_ |\n",
    "| B5 | 20 | red_edge_1<br>_B05 / B05_20m / band_5_ | B05<br>_band_05 / red_edge_1_ | nbar_red_edge_1<br>_nbar_band_05 / nbar_B05 / nbar_Band5_ |\n",
    "| B6 | 20 | red_edge_2<br>_B06 / B06_20m / band_6_ | B06<br>_band_06 / red_edge_2_ | nbar_red_edge_2<br>_nbar_band_06 / nbar_B06 / nbar_Band6_ |\n",
    "| B7 | 20 | red_edge_3<br>_B07 / B07_20m / band_7_ | B07<br>_band_07 / red_edge_3_ | nbar_red_edge_3<br>_nbar_band_07 / nbar_B07 / nbar_Band7_ |\n",
    "| B8 | 10 | nir<br>_B08 / B08_10m / band_8 / nir_1_ | B08<br>_band_08 / nir / nir_1_ | nbar_nir_1<br>_nbar_band_08 / nbar_B08 / nbar_Band8_ |\n",
    "| B8a | 20 | nir_narrow<br>_B8A / B8A_20m / band_8a / nir_2_ | B8A<br>_band_8a / nir_narrow / nir_2_ | nbar_nir_2<br>_nbar_band_8A / nbar_B8A / nbar_Band8A_ |\n",
    "| B9 | 60 | water_vapour<br>_B09 / B09_60m / band_09_ | B09<br>_band_09 / water_vapour_ | - |\n",
    "| B10 | 60 | - | - | - |\n",
    "| B11 | 20 | swir1<br>_B11 / B11_20m / band_11 / swir_1 / swir_16_ | B11<br>_band_11 / swir_1 / swir_16_ | nbar_swir_2<br>_nbar_band_11 / nbar_B11 / nbar_Band11_ |\n",
    "| B12 | 20 | swir2<br>_B12 / B12_20m / band_12 / swir_2 / swir_22_ | B12<br>_band_12 / swir_2, / swir_22_ | nbar_swir_3<br>_nbar_band_12 / nbar_B12 / nbar_Band12_ |\n",
    "| - | 20 | quality<br>_SCL / SCL_20m / mask / qa_ | SCL<br>_mask / qa_ | - |\n",
    "| - | - | - | - | fmask<br>_mask / Fmask_ |\n",
    "| - | 20 | aerosol_optical_thickness<br>_AOT / AOT_20m_ | AOT<br>_aerosol_optical_thickness_ | |\n",
    "| - | 20 | water_vapour_retrieval<br>_WVP / WVP_20m / scene_average_water_vapour_ | WVP<br>_scene_average_water_vapour_ | |\n",
    "| - | - | - | - | azimuthal_exiting |\n",
    "| - | - | - | - | azimuthal_incident |\n",
    "| - | - | - | - | exiting |\n",
    "| - | - | - | - | incident |\n",
    "| - | - | - | - | relative_azimuth |\n",
    "| - | - | - | - | relative_slope |\n",
    "| - | - | - | - | satellite_azimuth |\n",
    "| - | - | - | - | satellite_view |\n",
    "| - | - | - | - | solar_azimuth |\n",
    "| - | - | - | - | solar_zenith |\n",
    "| - | - | - | - | terrain_shadow |\n",
    "| - | - | - | - | nbar_contiguity |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EC Copernicus Data Hub\n",
    "\n",
    "https://scihub.copernicus.eu\n",
    "\n",
    "EC Copernicus Data Hub is the primary source of S2 L1B and L2A (Sen2cor) data. L2A (Sen2cor) is available globally from December 2018 onwards.\n",
    "\n",
    "Atmospheric correction - Sen2cor\n",
    "- Detailed summary of bands and thresholds for classification: https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm\n",
    "- Details of Sen2cor paramaters: https://sentinels.copernicus.eu/documents/247904/685211/Sen2-Cor-L2A-Input-Output-Data-Definition-Document\n",
    "\n",
    "Atmospheric correction - Any other method, including Sen2cor prior to December 2018\n",
    "- EASI can inject just about any preprocessing routine into our data preparation pipeline. That is, we would download S2 L1B and apply a preprocessing routine (an atmospheric correction method). This would create a new product name like ```cophub_s2_[type]_[routine]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentinel-2 Cloud-Optimized GeoTIFFs\n",
    "\n",
    "https://registry.opendata.aws/sentinel-2-l2a-cogs/\n",
    "\n",
    "Open and free S2 L2a (Sen2cor) COGs. Same time range as from CopHub (December 2018 onwards).\n",
    "\n",
    "TODO: Check the latency between CopHub and AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geoscience Australia NBAR-corrected for Australia\n",
    "\n",
    "_Adapted from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/DEA_datasets/Sentinel_2.ipyn\n",
    "\n",
    "Digital Earth Australia (DEA) applies corrections to Sentinel-2 satellite images to arrive at a [surface reflectance](https://cmi.ga.gov.au/ga_s2_m_nbart_1) product (see the [introduction to Digtial Earth Australia](../Beginners_guide/02_DEA.ipynb) section for more information on the surface reflectance corrections).\n",
    "Surface reflectance provides standardised optical datasets by using robust physical models to correct for variations in image radiance values due to atmospheric properties, as well as sun and sensor geometry.\n",
    "The resulting stack of surface reflectance grids are consistent over space and time, which is instrumental in identifying and quantifying environmental change.\n",
    "\n",
    "DEA provides two Sentinel-2 surface reflectance products:\n",
    "\n",
    "- **Sentinel-2 Definitive** (e.g. `s2a_ard_granule`): These products represent the 'definitive' source of high quality Sentinel-2 surface reflectance data, and are available from the beginning of the Sentinel-2 archive up to a delay of several weeks. \n",
    "\n",
    "- **Sentinel-2 Near Real Time** (e.g. `s2a_nrt_granule`): These products are processed with best-available ancillary information and provided as a rolling 90 day archive of imagery which is typically available to load within approximately ~24 hours of a satellite overpass.\n",
    "\n",
    "Both Sentinel-2 Definitive and Sentinel-2 Near Real Time products contain data processed to two surface reflectance corrections:\n",
    "\n",
    "- **NBAR** (e.g. `nbar_green`): NBAR stands for Nadir-corrected BRDF Adjusted Reflectance, where BRDF stands for Bidirectional reflectance distribution function.\n",
    "    The approach involves atmospheric correction to compute surface-leaving radiance and bi-directional reflectance modelling to remove the effects of topography and angular variation in reflectance.\n",
    "\n",
    "- **NBAR-T** (e.g. `nbart_green`): Surface reflectance NBAR-T includes the terrain illumination reflectance correction and has the same features of NBAR, along with some additional features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
