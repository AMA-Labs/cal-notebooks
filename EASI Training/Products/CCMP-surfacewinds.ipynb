{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72acfc67",
   "metadata": {},
   "source": [
    "# Cross-Calibrated Multi-Platform (CCMP) ocean surface wind 6-hourly, Version 2 (RSS) <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "_Work in progress_\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b9a32",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Cross-Calibrated Multi-Platform (CCMP) gridded surface vector winds are produced using satellite, moored buoy, and model wind data, and as such, are considered to be a Level-3 ocean vector wind analysis product. CCMP V2.0 is created by Remote Sensing Systems (RSS), as an update to the version 1 CCMP product, using improved and additional input data.\n",
    "\n",
    "Please include the following statement in the acknowledgement section of your paper:\n",
    "\"CCMP Version-2.0 analyses are produced by Remote Sensing Systems and sponsored by NASA Earth Science funding. Data are available at www.remss.com .\" (http://data.remss.com/ccmp/readme_ccmp.pdf)\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "Version 2 documentation: http://www.remss.com/measurements/ccmp\n",
    "- Current (June 2021) version 2 data extend from 1987 to 2019/04. We have processed and indexed 2000-2019 data; for brevity while the data are assessed and for reasonable comparison with other satellite data series.\n",
    "- RSS provide a \"v2.0 + NRT\" version that extends the series from 2015 to present; see the documentation link on the RSS website. Please let us know if the \"v2.0 + NRT\" dataset is required for your project, and we will look to add it as a separate product.\n",
    "\n",
    "Version 1 documentation: http://podaac.jpl.nasa.gov/dataset/CCMP_MEASURES_ATLAS_L4_OW_L3_0_WIND_VECTORS_FLK\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "Data are downloaded from https://podaac-tools.jpl.nasa.gov/drive/files/allData/ccmp/rss/v2.0/historical. These data are equivalent to those available from RSS.\n",
    "\n",
    "| Task | Summary |\n",
    "|------|---------|\n",
    "| Source | https://podaac-tools.jpl.nasa.gov/drive/files/allData/ccmp/rss/v2.0/historical |\n",
    "| Download | 2000-2019 |\n",
    "| Preprocess | Separate time layers into Tifs|\n",
    "| Format | COG |\n",
    "| Prepare | Y |\n",
    "| TODO | Update to 6-hourly indexing |\n",
    "\n",
    "__Note__: Data are currently (first cut) organised and indexed on a per day basis, with 6-hourly fields available as [variable]_[hour] (e.g., `uwind_00`). It would be better if the 6-hourly fields were indexed with their `day + 6-hourly` timestamp and variables were then available as `uwind`. We have a plan to do this fairly easily; just need to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872cc103",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c51baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.0.57.215:34417\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba51859",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a96ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('~/hub-notebooks/scripts'))\n",
    "import notebook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cad1fd",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00230705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development products:\n",
    "#  - This is a development ODC database while we test and demo this product.\n",
    "CONF = \"\"\"\n",
    "[datacube]\n",
    "db_hostname: v2-db-easihub-csiro-eks.cluster-ro-cvaedcg0qvwd.ap-southeast-2.rds.amazonaws.com\n",
    "db_database: user_dev_odc\n",
    "db_username: user\n",
    "db_password: secretpassword\n",
    "\"\"\"\n",
    "from datacube.config import read_config, LocalConfig\n",
    "dc = datacube.Datacube(config=LocalConfig(read_config(CONF)), env='datacube')\n",
    "\n",
    "# dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e3fb5",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "\n",
    "Change any of the parameters in the query object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product:\n",
    "- https://explorer.csiro.easi-eo.solutions  + /product (when available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f58791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area name\n",
    "min_longitude, max_longitude = (0,360)\n",
    "min_latitude, max_latitude = (-80,80)\n",
    "min_date = '2000-01-01'\n",
    "max_date = '2019-05-01'\n",
    "product = 'ccmp_surfacewind_l3v2'\n",
    "\n",
    "native_crs = 'epsg:4326'\n",
    "\n",
    "query = {\n",
    "    'product': product,                     # Product name\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (0.25, 0.25),             # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'latitude': 2048, 'longitude': 2048},  # Dask chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29566be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Some products require AWS S3 credentials to supplied\n",
    "\n",
    "# S3 credentials - required for s2_l2a\n",
    "# configure_s3_access(aws_unsigned=True,requester_pays=False,client=client)\n",
    "# print(\"Configured s3 requester pays data access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452a818",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf4e23",
   "metadata": {},
   "source": [
    "## Quality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No quality layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f669be",
   "metadata": {},
   "source": [
    "## Roll longitudes to -180,180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust longitudes to -180,180 for plotting with geoviews/datashader\n",
    "# https://discourse.holoviz.org/t/with-longitude-0-360-data-briefly-appears-on-map-then-disappears-also-hover-broken/1213/2\n",
    "\n",
    "def roll_longitude(data: xr.Dataset, name: str):\n",
    "    if max(data['longitude']) > 180:\n",
    "        print(f'Rolling: {name}')\n",
    "        data = data.roll(longitude=int(data.sizes['longitude']/2), roll_coords=False)\n",
    "        data['longitude'] = data['longitude']-180\n",
    "        display(min(data['longitude']).values, max(data['longitude']).values)\n",
    "    return data\n",
    "    \n",
    "data_roll = roll_longitude(data, 'data')\n",
    "valid_mask_roll = roll_longitude(valid_mask, 'valid_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b147587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test that the roll is working correctly\n",
    "#\n",
    "# with np.printoptions(threshold=np.inf, precision=3, linewidth=160, formatter={'float':lambda x:f'{x:0.3f}'}):\n",
    "#     for x in range(int(1440/20)):\n",
    "#         print(f'{x:4d}: {data[\"uwind_00\"][0,10,x*20:(x+1)*20].values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878844cb",
   "metadata": {},
   "source": [
    "## Masking and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a589b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'uwind_00'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data_roll[[layer_name]].where(valid_mask_roll[layer_name])\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018ec0d",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099525ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a plot\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 800,\n",
    "    'height': 400,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': cc.rainbow,\n",
    "    'clim': (-25, 25),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'longitude', y = 'latitude',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                        # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b6604",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619bcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
