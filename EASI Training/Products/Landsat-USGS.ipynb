{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat <img align=\"right\" src=\"../../resources/easi_logo.jpg\">\n",
    "\n",
    "_Work in progress_\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Landsat 5, 7 and 8 products provided by USGS. USGS make Landsat data available via number of services, including:\n",
    "- Earth Explorer, https://earthexplorer.usgs.gov\n",
    "- ESPA, https://espa.cr.usgs.gov/\n",
    "\n",
    "https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "Landsat 5, 7 versions of each of these are also available.\n",
    "\n",
    "| Name | Product | Information\n",
    "|--|--|--|\n",
    "| USGS AWS surface reflectance (collection 2) | usgs_aws_ls8c2_sr | https://www.usgs.gov/core-science-systems/nli/landsat/landsat-commercial-cloud-data-access\n",
    "| USGS ESPA surface reflectance (collection 1) | usgs_espa_ls8c1_sr | https://www.usgs.gov/core-science-systems/nli/landsat/landsat-surface-reflectance\n",
    "| USGS ESPA aquatic reflectance (collection 1) | usgs_espa_ls8c1_ar | https://www.usgs.gov/core-science-systems/nli/landsat/landsat-provisional-aquatic-reflectance\n",
    "| GA Landsat ARD (Australia coverage) | |\n",
    "\n",
    "The Collection 1 Level 1, [TOA](https://www.usgs.gov/core-science-systems/nli/landsat/using-usgs-landsat-level-1-data-product) and [Spectral indices](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-surface-reflectance-derived-spectral-indices) ESPA products are also available.\n",
    "\n",
    "| Product | Indices |\n",
    "|--|--|\n",
    "| usgs_espa_ls8c1_l1 | Level 1\n",
    "| usgs_espa_ls8c1_toa | Top of Atmosphere\n",
    "| usgs_espa_ls8c1_veg | Normalized Difference Vegetation Index (NDVI)<br>Enhanced Vegetation Index (EVI)\n",
    "| usgs_espa_ls8c1_soil | Soil Adjusted Vegetation Index (SAVI)<br>Modified Soil Adjusted Vegetation Index (MSAVI)\n",
    "| usgs_espa_ls8c1_burn | Normalized Difference Moisture Index (NDMI)<br>Normalized Burn Ratio (NBR)<br>Normalized Burn Ratio 2 (NBR2)\n",
    "\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "| Task | usgs_espa_ls8c1_sr | usgs_espa_ls8c1_ar |\n",
    "|--|--|--|\n",
    "| Source | | |\n",
    "| Download | | |\n",
    "| Preprocess | | |\n",
    "| Format | | |\n",
    "| Prepare | | |\n",
    "| TODO | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.0.91.72:36317\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from odc.algo import xr_reproject   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_warp.py\n",
    "from datacube.utils.geometry import GeoBox, box  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/geometry/_base.py\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False)\n",
    "\n",
    "# Python\n",
    "import sys, os, re\n",
    "\n",
    "# Optional EASI tools\n",
    "sys.path.append(os.path.expanduser('~/hub-notebooks/scripts'))\n",
    "import notebook_utils\n",
    "import datacube_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vietnam - Ha Long\n",
    "min_longitude, max_longitude = (106.7, 107.7)\n",
    "min_latitude, max_latitude = (20.7, 21.1)\n",
    "min_date = '2019-01-01'\n",
    "max_date = '2019-07-31'\n",
    "product = 'usgs_espa_ls8c1_sr'\n",
    "\n",
    "query = {\n",
    "    'product': product,                     # Product name\n",
    "    'x': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "    'y': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "    'time': (min_date, max_date),           # Any parsable date strings\n",
    "}\n",
    "\n",
    "# Most common CRS\n",
    "native_crs = notebook_utils.mostcommon_crs(dc, query)\n",
    "print(f'Native CRS: {native_crs}')\n",
    "\n",
    "query.update({\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (30, 30),                # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'x': 2048, 'y': 2048},  # Dask chunks\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Some products require AWS S3 credentials to supplied\n",
    "\n",
    "# S3 credentials - required for s2_l2a\n",
    "# configure_s3_access(aws_unsigned=True,requester_pays=False,client=client)\n",
    "# print(\"Configured s3 requester pays data access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Filter Datasets prior to Load\n",
    "\n",
    "# For example, to load only Tier 1 (best quality) datasets and exclude Tier 2 (good quality).\n",
    "# See https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collection-1 for a description of Landsat processing Tiers.\n",
    "\n",
    "# 1. Remove load parameters from query object\n",
    "# Borrowed from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py\n",
    "\n",
    "# non_load_query = datacube_utils.dc_query_only(**query)\n",
    "# dataset_list = dc.find_datasets(**non_load_query)\n",
    "\n",
    "# 2. Check your query has results\n",
    "# Borrowed from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py\n",
    "\n",
    "# if len(dataset_list) == 0:\n",
    "#    print(\"No data available for query: ensure that \"\n",
    "#          \"the products specified have data for the \"\n",
    "#          \"time and location requested\")\n",
    "\n",
    "# 3. Check what details are available in each dataset\n",
    "# See https://github.com/opendatacube/datacube-core/blob/develop/datacube/model/__init__.py, class Dataset\n",
    "# display(datasets[0].__dict__)\n",
    "\n",
    "# 4. Filter based on property of interest\n",
    "# For Landsat, the Tier label is available in the 'landsat:collection_category' property\n",
    "\n",
    "# dataset_list = [ds for ds in dataset_list if ds.metadata_doc['properties']['landsat:collection_category'] == 'T1']\n",
    "# if len(dataset_list) == 0:\n",
    "#    print(\"No data available after filtering\")\n",
    "\n",
    "# 5. Update query object for next cell\n",
    "# 'datasets' will used instead of the standard database lookup\n",
    "\n",
    "# query['datasets'] = dataset_list\n",
    "# query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)  # Default pandas table display. Some rows or columns may be abbreviated\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make L2_FLAGS image\n",
    "flag_name = 'pixel_qa'\n",
    "flag_data = data[[flag_name]].where(valid_mask[flag_name]).persist()   # Dataset\n",
    "display(flag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drat!\n",
    "## Geoviews/Cartopy projection from epsg:32649 to PlateCarree doesn't work (works for S2 UTM)\n",
    "##\n",
    "\n",
    "# These options manipulate the color map and colorbar to show the categories for this product\n",
    "options = {\n",
    "    'title': f'Flag data for: {query[\"product\"]} ({flag_name})',\n",
    "    'cmap': cc.rainbow,\n",
    "    'colorbar': True,\n",
    "    'width': 700,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "quality_plot = flag_data.hvplot.image(\n",
    "    x = 'x', y = 'y',         # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mode(),          # Datashader selects mode value, requires 'hv.Image'\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset CRS\n",
    "    projection = ccrs.PlateCarree(),         # Output Projection (ccrs.PlateCarree() when coastline=True)\n",
    "    coastline = '10m',                       # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist()\n",
    "\n",
    "# display(quality_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(quality_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask layer\n",
    "\n",
    "# \"L3 Mask Default\"\n",
    "good_pixel_flags = {\n",
    "    'snow': 'no_snow',                    # 'no_snow', 'snow'\n",
    "#     'clear': 'clear_land',                # 'no_clear_land', 'clear_land'\n",
    "    'cloud': 'no_cloud',                  # 'no_cloud', 'cloud'\n",
    "#     'water': 'water',                     # 'no_water', 'water'\n",
    "    'nodata': False,                      # False, True\n",
    "    'cloud_shadow': 'no_cloud_shadow',    # 'no_cloud_shadow', 'cloud_shadow'\n",
    "#     'cloud_confidence': 'medium',         # 'none', 'low', 'medium', 'high'\n",
    "#     'cirrus_confidence': 'medium',        # 'none', 'low', 'medium', 'high'\n",
    "#     'terrain_occlusion': 'no_occlusion',  # 'no_occlusion', 'occlusion'\n",
    "}\n",
    "\n",
    "good_pixel_mask = masking.make_mask(data[flag_name], **good_pixel_flags)  # -> bool array\n",
    "display(good_pixel_mask)  # Type: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling\n",
    "\n",
    "# usgs_espa_ls8c1_sr, usgs_espa_ls8c1_ar\n",
    "scale = 0.0001\n",
    "offset = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'nir'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data[[layer_name]].where(valid_mask[layer_name] & good_pixel_mask) * scale + offset\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drat!\n",
    "## Geoviews/Cartopy projection from epsg:32649 to PlateCarree doesn't work (works for S2 UTM)\n",
    "##\n",
    "\n",
    "# Generate a plot\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 1000,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': cc.rainbow,\n",
    "    'clim': (0, 0.05),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "    \n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'x', y = 'y',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)\n",
    "\n",
    "# Good image of Sarawak: 2020-01-27 0555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Reference material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter datasets\n",
    "\n",
    "# From load_ard()\n",
    "datasets = dc.find_datasets(product=product, **query)\n",
    "\n",
    "# Remove datasets after the Landsat 7 SLC failure, May 31 2003.\n",
    "if product in ('ga_ls7e_ard_3', 'usgs_espa_ls7c1_sr'):\n",
    "    datasets = [i for i in datasets if\n",
    "                normalise_dt(i.time.begin) <\n",
    "                datetime.datetime(2003, 5, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking and Scaling\n",
    "\n",
    "# dea-notebooks/Real_world_examples/ARD_Intercomparison/utilities/util.py\n",
    "\n",
    "ls8_USGS_cloud_pixel_qa_value = [324, 352, 368, 386, 388, 392, 400, 416, \n",
    "                                     432, 480, 864, 880, 898, 900, 904, 928, \n",
    "                                     944, 992, 1350]\n",
    "non_ls8_USGS_cloud_pixel_qa_value = [72, 96, 112, 130, 132, 136, 144, 160, \n",
    "                                         176, 224]\n",
    "    non_ls8_USGS_sr_cloud_qa_value = [2, 4, 12, 20, 34, 36, 52]\n",
    "\n",
    "mask_data = data[mask_band]\n",
    "    nodata_value = mask_data.nodata\n",
    "    nodata_cloud_value = []\n",
    "    \n",
    "    if 'usgs' in source_prod:\n",
    "        if 'ls8' in source_prod:\n",
    "            nodata_cloud_value = ls8_USGS_cloud_pixel_qa_value\n",
    "        else:\n",
    "            if mask_band == 'sr_cloud_qa':\n",
    "                nodata_cloud_value = non_ls8_USGS_sr_cloud_qa_value\n",
    "            else:\n",
    "                nodata_cloud_value = non_ls8_USGS_cloud_pixel_qa_value\n",
    "                \n",
    "        nodata_cloud_value.append(nodata_value)\n",
    "        nodata_cloud = np.isin(mask_data, nodata_cloud_value) \n",
    "        cld_free = data.where(~nodata_cloud).dropna(dim='time', how='all')\n",
    "        \n",
    "    # remove nodata for the pixel of interest\n",
    "    cld_free_valid = masking.mask_invalid_data(cld_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
