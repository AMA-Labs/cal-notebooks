{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02687e39",
   "metadata": {},
   "source": [
    "# Hello CEOS EAIL <img align=\"right\" src=\"../resources/csiro_easi_logo.png\">\n",
    "\n",
    "This notebook will introduce new users to working with the Open Data Cube and CEOS EAIL Jupyter notebooks.\n",
    " \n",
    "It will demonstrate the following basic functionality:\n",
    "- [Notebook setup](#Notebook-setup)\n",
    "  - [Dask computing environment](#Dask-computing-environment)\n",
    "  - [Access public requester pays buckets](#Access-public-requester-pays-buckets)\n",
    "- [Connect to the OpenDataCube](#Connect-to-the-OpenDataCube)\n",
    "  - [List available products](#List-available-products)\n",
    "  - [List all measurements](#List-all-measurements)\n",
    "  - [Load some data](#Load-some-data)\n",
    "  - [Plot the data](#Plot-the-data)\n",
    "  - [Scaling factor (Landsat)](#Scaling-factor-(Landsat))\n",
    "  - [Apply a cloud mask to data](#Apply-a-cloud-mask-to-the-data)\n",
    "  - [Perform a computation on the data](#Perform-a-computation-on-the-data)\n",
    "  - [Save the results to a file](#Save-the-results-to-file)\n",
    "  - [Resources](#Resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197ad26",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "A notebook consists of cells that contain either text descriptions or python code for performing operations on data.\n",
    "\n",
    "Start by clicking on the cell below to select it. Then execute a selected cell (or each cell in sequence) by clicking the \"play\" button (in the toolbar above) or pressing `Shift`+`Enter`.\n",
    "\n",
    "Each cell will show an asterisk icon <font color='#999'>[*]:</font> when it is running. Once this changes to a number, the cell has finished.\n",
    "\n",
    "This cell below does some optional setup to format the outputs.\n",
    "> Note: We use matplotlib here as a baseline example. Other notebooks in this tutorial may use interactive plotting libraries (e.g., Holoviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd060e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formatting for basic plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.rc = {}\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# Formatting pandas table output\n",
    "import pandas\n",
    "pandas.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30daf2-b6af-44c7-b0f5-26b2b277de6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EASI tools\n",
    "import git\n",
    "import sys, os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "if repo.working_tree_dir not in sys.path: sys.path.append(repo.working_tree_dir + '/scripts')\n",
    "from easi_tools import EasiDefaults\n",
    "import notebook_utils\n",
    "easi = EasiDefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe13233",
   "metadata": {},
   "source": [
    "## Dask computing environment\n",
    "\n",
    "In EASI, each notebook starts by defining a Dask cluster for the notebook to use.\n",
    "\n",
    "> For more information regarding Dask, see [A2 - Dask](A2%20-%20Dask.ipynb).\n",
    "\n",
    "The are two main methods for setting up your dask cluster: \n",
    "1. **Local dask cluster**\n",
    "    - Provides a dask multiprocessing environment on your Jupyter node. Useful for processing data volumes that don't exceed the Jupyter node limits, which are currently set at `cores = 8, memory = 32 GB` (2x large)\n",
    "\n",
    "\n",
    "1. **Dask Gateway**\n",
    "    - Provides a scalable compute cluster in EASI for your use. You can (*should*) use the same cluster across each of your notebooks (a separate cluster per notebook would unnessarily use EASI resources).\n",
    "    - For most notebooks and data analysis start with `2 to 4 workers` (adaptive). Dask gateway is limited to 20 workers per user.\n",
    "    - It is normal for this step to take **3 to 5 minutes** if new computing nodes need to be generated\n",
    "\n",
    "**This notebook will just use a local cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b159c",
   "metadata": {},
   "source": [
    "### Local dask cluster\n",
    "\n",
    "For local cluster options, see https://docs.dask.org/en/latest/setup/single-distributed.html\n",
    "\n",
    "The Dask Dashboard link shown after the following cell is a helpful resource to explore the activity and state of your dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8389ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster, client = notebook_utils.initialize_dask(use_gateway=False)\n",
    "display(cluster if cluster else client)\n",
    "print(notebook_utils.localcluster_dashboard(client, server=easi.hub))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a035556",
   "metadata": {},
   "source": [
    "## Access public requester pays buckets\n",
    "\n",
    "EASI OpenDataCube can index and use datasets stored in public S3 \"requester pays\" buckets. Requester pays means that use of the data is charged at the time of use. The charges are relatively low for normal exploratory analysis and within the same Data Center.\n",
    "\n",
    "> For larger analyses or between Data Centers please contact us for advice as there may be more cost-effective ways to do your analysis that we can explore with you.\n",
    "\n",
    "To use data in public requester pays buckets, run the following code (once per dask cluster):\n",
    "\n",
    "**All Landsat (e.g. landsat5_c2l2_sr, landsat9_c2l2_st, etc) and Sentinel-2 (s2_l2a) products require this setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06247cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"This function obtains credentials for S3 access and passes them on to\n",
    "   processing threads, either local or on dask cluster.\n",
    "   Note that AWS credentials may need to be renewed between sessions or\n",
    "   after a period of time.\"\"\"\n",
    "\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True, client=client)\n",
    "\n",
    "# If not using a dask cluster then remove 'client':\n",
    "# configure_s3_access(aws_unsigned=False, requester_pays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01615",
   "metadata": {},
   "source": [
    "## Connect to the OpenDataCube\n",
    "Your EASI Hub environment has been setup with default credentials to access the EASI OpenDataCube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d3de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datacube\n",
    "dc = datacube.Datacube()\n",
    "datacube.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931f18e",
   "metadata": {},
   "source": [
    "### List available products\n",
    "\n",
    "Get all available products and list them along with selected properties.\n",
    "\n",
    "> View available products and data coverage at the EAIL Explorer: https://explorer.eail.easi-eo.solutions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacf0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products = dc.list_products()\n",
    "\n",
    "# The output of list_products() changed between datacube versions 1.8.4 and 1.8.6\n",
    "selected_columns = products.columns\n",
    "if 'default_crs' not in selected_columns:\n",
    "    selected_columns = [\"name\", \"description\", \"platform\", \"crs\", \"resolution\"]\n",
    "products[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7c575",
   "metadata": {},
   "source": [
    "### List all measurements\n",
    "Get all product measurements and list them along with selected properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b30e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "measurements = dc.list_measurements()\n",
    "measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b9bb6",
   "metadata": {},
   "source": [
    "### Load some data \n",
    "Load some data using the default configuration for this environment.\n",
    "\n",
    "The resulting `DataSet` contains data for all bands of the Surface Reflectance within the specified location/time range.  \n",
    "\n",
    "Feel free to change the `latitude`/`longitude` or `time` ranges of the query below. The `output_crs` and `resolution` parameters are dependent on the `product` chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f17e5a-6f7a-4b8f-a565-2e7d5bda25b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This configuration is read from the defaults for this system. \n",
    "# Examples are provided in a commented line to show how to set these manually.\n",
    "\n",
    "study_area_lat = easi.latitude\n",
    "# study_area_lat = (39.2, 39.3)\n",
    "\n",
    "study_area_lon = easi.longitude\n",
    "# study_area_lon = (-76.7, -76.6)\n",
    "\n",
    "product = easi.product('landsat')\n",
    "# product = 'landsat8_c2l2_sr'\n",
    "\n",
    "set_time = easi.time\n",
    "# set_time = ('2020-08-01', '2020-12-01')\n",
    "\n",
    "set_crs = easi.crs('landsat')\n",
    "# set_crs = 'EPSG:32618'\n",
    "\n",
    "set_resolution = easi.resolution('landsat')\n",
    "# set_resolution = (-30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1d11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hub.eail.easi-eo.solutions - Baltimore\n",
    "data = dc.load(\n",
    "    product=product, \n",
    "    latitude=study_area_lat,\n",
    "    longitude=study_area_lon,\n",
    "    time=set_time,\n",
    "    output_crs=set_crs,\n",
    "    resolution=set_resolution,\n",
    "    group_by='solar_day',\n",
    "    dask_chunks={'time':1} # For more on this line, see \"A2 - Dask\"\n",
    ")\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659abb32",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "Plot the `\"swir22\"` band data at each timestep\n",
    "\n",
    "- At some timesteps data is only available for part of the specified area so we mask the missing data. \n",
    "- The `robust=True` option instructs the plotting function to ignore outliers in applying the colourmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454a178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xarray operations\n",
    "\n",
    "valid_data = data[\"swir22\"] != data[\"swir22\"].nodata\n",
    "data[\"swir22\"].where(valid_data).plot(col=\"time\", robust=True, col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca6ce3",
   "metadata": {},
   "source": [
    "### Scaling factor (Landsat)\n",
    "Landsat data requires a scale factor to be applied to convert the data to sensible reflectance or temperature values. Once converted, Landsat surface reflectance values will have numbers ranging from 0 to 1 and surface temperature values will be in the units of degrees Kelvin. The scaling factor is different for different Landsat \"Collections\" and it is different for the Surface Reflectance and Surface Temperature products. The code below scales the surface reflectance values for Landsat \"Collection 2\" data which is being used in this notebook.\n",
    "\n",
    "See https://www.usgs.gov/faqs/how-do-i-use-a-scale-factor-landsat-level-2-science-products for more information\n",
    "\n",
    "Once plotted, the data below will show a scale of between 0 and 1 (depending on the data) rather than the large numbers in the images above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2b036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the surface reflectance bands\n",
    "\n",
    "# hub.csiro.easi-eo.solutions\n",
    "product = product\n",
    "measurement = 'swir22'\n",
    "scale_factor = 0.0000275\n",
    "add_offset = -0.2\n",
    "\n",
    "sr_measurements = measurements.loc[measurements['units'] == 'reflectance']\n",
    "sr_bands = sr_measurements.loc[product].index.values\n",
    "# Apply the scaling factor\n",
    "normalised_sr = data\n",
    "normalised_sr.update(data[sr_bands] * scale_factor + add_offset)\n",
    "normalised_sr[measurement].where(valid_data).plot(col='time', robust=True, col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba13535",
   "metadata": {},
   "source": [
    "### Apply a cloud mask to the data\n",
    "\n",
    "We can use the Landsat pixel quality band to create a cloud mask.\n",
    "\n",
    "> For more information on cloud masking, see [04 - Masking Data](./04%20-%20Masking%20Data.ipynb).\n",
    "\n",
    "Then we can plot the `\"swir22\"` data again with clouds masked out, this time for a single timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc7fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ODC masking, xarray operations\n",
    "\n",
    "from datacube.utils import masking\n",
    "# display(masking.describe_variable_flags(data))\n",
    "\n",
    "good_pixel_flags = {\n",
    "    'nodata': False,\n",
    "    'cloud': 'not_high_confidence',\n",
    "    'cloud_shadow': 'not_high_confidence',\n",
    "    'water': 'land_or_cloud'\n",
    "}\n",
    "cloud_mask = masking.make_mask(normalised_sr['qa_pixel'], **good_pixel_flags)\n",
    "data_masked = normalised_sr[measurement].where(cloud_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c636fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_masked.isel(time=1).plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cb0a4",
   "metadata": {},
   "source": [
    "### Perform a computation on the data\n",
    "After scaling and masking, we apply calculations or algorithms to the data.\n",
    "\n",
    "As a simple example, we calculate the Normalized Difference Vegetation Index (NDVI) from the Surface Reflectance data we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91507f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the NDVI\n",
    "band_diff = normalised_sr.nir08 - normalised_sr.red\n",
    "band_sum = normalised_sr.nir08 + normalised_sr.red\n",
    "ndvi = band_diff / band_sum\n",
    "\n",
    "# Plot the masked NDVI\n",
    "ndvi.where(cloud_mask).isel(time=1).plot(robust=True,cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ee686",
   "metadata": {},
   "source": [
    "### Save the results to file\n",
    "After processing the data we can then save the output to a file that can then be imported into other applications for further analysis or publication if required.\n",
    "\n",
    "The file will be saved to your home directory and appear on the File Browser panel to the left. You may need to select the `folder` icon to go to the top level (`~/` or `/home/jovyan/`).\n",
    "\n",
    "Download a file by `'right-click' Download`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562c048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xarray can save the data to a netCDF file\n",
    "\n",
    "ndvi.time.attrs.pop('units', None)  # Required until ODC 1.8.1 installed\n",
    "ndvi.load()                         # Load the data into memory from Dask so that it can written to file\n",
    "ndvi.to_netcdf(\"~/landsat8_sr_ndvi.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26236c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or export to geotiff using rioxarray.\n",
    "\n",
    "import rioxarray\n",
    "ndvi.isel(time=0).rio.to_raster(\"/home/jovyan/landsat8_sr_ndvi.tif\") # Note that a single time slice has been selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5db6be",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "The EASI Hub environment is built from a number components. Below are a number of links which might help make better use of this environment.\n",
    "\n",
    "\n",
    "#### Open Data Cube\n",
    "\n",
    "Open Data Cube (ODC) is the open source software that EASI Hub uses to enable users to manage and analyse vast amounts of Earth Observation data. Visit the [Open Data Cube](https://www.opendatacube.org) website for tutorials and videos. See also:\n",
    "- [ODC documentation](https://datacube-core.readthedocs.io/en/latest)\n",
    "- [ODC github](https://github.com/opendatacube)\n",
    "\n",
    "\n",
    "#### JupyterLab\n",
    "\n",
    "Visit the [JupyterLab documentation website](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html) where they have an overview explaining the basics of working within the JupyterLab environment. \n",
    "\n",
    "\n",
    "#### GIT\n",
    "\n",
    "Notebooks and associated code are managed with GIT version control system. You have seen already how to \"clone\" the git repository containing these notebooks into your EASI Hub home drive.\n",
    "- [JupyterLab Git plugin tutorial](https://annefou.github.io/jupyter_publish/02-git/index.html)\n",
    "- [Geoscience Australia Git tutorial](https://github.com/GeoscienceAustralia/dea-notebooks/wiki/Guide-to-using-DEA-Notebooks-with-git)\n",
    "\n",
    "\n",
    "#### Python\n",
    "\n",
    "The code in this and other EASI Hub notebooks is written in [Python](https://www.python.org/) using the Open Data Cube python library.\n",
    "\n",
    "If you are new to Python there are many online tutorials to help you learn, including https://www.learnpython.org\n",
    "\n",
    "See below for some of the Python libraries used within EASI Hub notebooks\n",
    "\n",
    "- [datacube](https://datacube-core.readthedocs.io/en/latest/user/intro.html) - Python API for loading datasets from the Open Data Cube database.\n",
    "- [xarray](http://xarray.pydata.org/en/stable/why-xarray.html) - Allows processing of gridded datasets loaded from `datacube`.\n",
    "- [dask](https://docs.dask.org/en/latest/why.html) - Working with `xarray`, `dask` enables the distributed processing of very large datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc0c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
