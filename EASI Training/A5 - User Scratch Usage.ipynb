{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASI User Scratch bucket <img align=\"right\" src=\"../resources/csiro_easi_logo.png\">\n",
    " \n",
    "EASI has a \"scratch\" bucket available for all users. \"Scratch\" means temporary: all files __will be deleted after 30 days__. Use the scratch bucket to save files between processing runs or share files between projects, temporarily.\n",
    "\n",
    "If you need to share files and resources between projects beyond 30 days then consider provisioning a \"Project\" bucket. Contact the admins for details.\n",
    "\n",
    "Glossary:\n",
    "- S3 storage items are called \"**objects**\". Typically these are files but they could be any blob of data.\n",
    "- An object's name is its \"**key**\". The key can be any just about any string. Typically we include a `/` in the key to make it look like a directory path, which we're familiar with from regular file systems.\n",
    "- `boto3` is the underlying library to interact with AWS services.\n",
    "\n",
    "Best practice:\n",
    "1. Prepend a name to your object(s) to aid organisation. That is, you will be able to find and reference your files.\n",
    "\n",
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('../scripts'))\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "from easi_tools import EasiDefaults\n",
    "easi = EasiDefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "scratch_bucket = easi.scratch_bucket\n",
    "print(f'Your temporary scratch bucket is s3://{scratch_bucket}')\n",
    "\n",
    "# Optional for this notebook: create a test file\n",
    "!touch '/home/jovyan/test-file.txt'\n",
    "\n",
    "# Optional, for parallel uploads and downloads of large files\n",
    "# from boto3.s3.transfer import TransferConfig\n",
    "# config = TransferConfig(\n",
    "#     multipart_threshold = 1024 * 25,\n",
    "#     max_concurrency = 10,\n",
    "#     multipart_chunksize = 1024 * 25,\n",
    "#     use_threads = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a name unique to your work\n",
    "\n",
    "Here we use your AWS UserID, which comes from your AWS credentials (auto-generated by EASI).\n",
    "\n",
    "You could also use your ident (AWS does not know your ident) or a project name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "userid = boto3.client('sts').get_caller_identity()['UserId']\n",
    "print(f'Your userid is {userid}')\n",
    "print(f'Your temporary scratch folder is s3://{scratch_bucket}/{userid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a file\n",
    "\n",
    "Two methods are shown here.\n",
    "1. Upload file, using `upload_file` function\n",
    "1. Upload a binary object, using `with` context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Upload file, using upload_file function. Includes a little more rigour in error catching etc.\n",
    "\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # boto3\n",
    "    if 's3' not in locals():\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "    # Upload the file\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket, object_name)  # Config=config\n",
    "    except (ClientError, FileNotFoundError) as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "jhub_file = '/home/jovyan/test-file.txt'\n",
    "res = upload_file(jhub_file, scratch_bucket, f'{userid}/test-file.txt')\n",
    "if res:\n",
    "    print(f'Successfully uploaded s3://{scratch_bucket}/{userid}/test-file.txt')\n",
    "else:\n",
    "    print('Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Upload a binary object, using `with` context\n",
    "\n",
    "# boto3\n",
    "if 's3' not in locals():\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "jhub_file = '/home/jovyan/test-file.txt'\n",
    "with open(jhub_file, 'rb') as f:\n",
    "    try:\n",
    "        r = s3.upload_fileobj(f, scratch_bucket, f'{userid}/test-file.txt')\n",
    "        print(f'Successfully uploaded s3://{scratch_bucket}/{userid}/test-file.txt')\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        print('Failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List objects in the scratch bucket\n",
    "\n",
    "The `boto3.list_objects_v2` function will return at most 1000 keys.\n",
    "\n",
    "Two options are shown here.\n",
    "1. Basic use of `list_objects_v2`\n",
    "2. Paginated list objects, for potentially >1000 keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic use of list_objects_v2\n",
    "\n",
    "# boto3\n",
    "if 's3' not in locals():\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=scratch_bucket,\n",
    "    Prefix=f'{userid}/',\n",
    ")\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(response)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for c in response['Contents']:\n",
    "        key = c['Key']\n",
    "        lastmodified = c['LastModified'].strftime('%Y-%d-%m %H:%M:%S')\n",
    "        print(f'{lastmodified}: s3://{scratch_bucket}/{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paginated list objects, for potentially >1000 keys\n",
    "\n",
    "# boto3\n",
    "if 's3' not in locals():\n",
    "    s3 = boto3.client('s3')\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "page_iterator = paginator.paginate(Bucket=scratch_bucket, Prefix=f'{userid}/')\n",
    "\n",
    "for response in page_iterator:\n",
    "    if 'Contents' in response:\n",
    "        for c in response['Contents']:\n",
    "            key = c['Key']\n",
    "            lastmodified = c['LastModified'].strftime('%Y-%d-%m %H:%M:%S')\n",
    "            print(f'{lastmodified}: s3://{scratch_bucket}/{key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve objects in scratch bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example, retrieve the first file from list_objects\n",
    "from pathlib import Path\n",
    "\n",
    "# boto3\n",
    "if 's3' not in locals():\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "response = s3.list_objects_v2(Bucket=scratch_bucket, Prefix=f'{userid}/')\n",
    "key = response['Contents'][0]['Key']  # First file (example)\n",
    "\n",
    "# jhub file name\n",
    "jhub_file = '/home/jovyan/' + Path(key).stem + '-downloaded.txt'\n",
    "\n",
    "try:\n",
    "    s3.download_file(scratch_bucket, key, str(jhub_file))  # Config=config\n",
    "    print(f'Successly downloaded {jhub_file}')\n",
    "except Exception as e:\n",
    "    logging.error(e)\n",
    "    print('Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
