{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Wildfires in California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQkxgiAHnoPLQCy3-Z68vLAWbczrKCDJ37VGV0cKXBUOP9IBNZ8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "A **wildfire** is an uncontrolled fire in the vegetation of an area, also commonly referred to as a forest fire, bushfire, grassfire, veldfire, etc., depending on type of vegetation burning and/or where you live. California has dry, windy, and often hot weather conditions from spring through late autumn that can produce moderate to devastating wildfires. At times, these wildfires are fanned or made worse by strong, dry winds, known as Diablo winds when they occur in the northern part of the state and Santa Ana winds when they occur in the south. Wildfires in California are growing increasingly dangerous because of climate change and because more people are building in rural burn areas. So far, **in 2019, over 6,402 fires have been recorded** according to Cal Fire and the US Forest Service, totaling an estimated of 250,349 acres (101,313 ha) of burned land as of November 3.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "The wildfire once begun, quickly spreads, consuming the thick, dried-out vegetation and almost everything else in its path. What was once a forest becomes a virtual powder keg of untapped fuel. In a seemingly instantaneous burst, the wildfire overtakes thousands of acres of surrounding land, threatening the homes and lives of many in the vicinity. These rolling flames travel up to 14 miles an hour, which converts to about a four-minute mile pace, and can overtake the average human in minutes, and that makes it *important to detect wild fires at the earliest* which helps to regulate them and in turn provides more evacuation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore some innocuous warnings.\n",
    "import warnings\n",
    "import sys\n",
    "import logging\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.CRITICAL)\n",
    "for logger_name in ('boto', 'boto3', 'botocore', 's3transfer', 'rasterio', 'dask', \n",
    "                    'distributed', 'distributed.core', 'distributed.scheduler', 'distributed.client',\n",
    "                    'distributed.batched', 'urllib3'):\n",
    "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)\n",
    "    \n",
    "import dask\n",
    "import distributed\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "cluster = None\n",
    "# Click on the 'Dashboard link' to monitor calculation progress\n",
    "cluster = KubeCluster()\n",
    "cluster.scale_up(12)\n",
    "client = distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import datacube\n",
    "import datetime\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "\n",
    "sys.path.append('../CEOS Notebooks')\n",
    "from datacube.storage import masking\n",
    "import utils.data_cube_utilities.data_access_api as dc_api \n",
    "from utils.data_cube_utilities.dc_load import get_overlapping_area\n",
    "from utils.data_cube_utilities.dc_display_map import display_map \n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Datacube\n",
    "dc = datacube.Datacube(app=\"Fire Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parametes\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "The parameters are\n",
    "\n",
    "* `latitude`: The latitude range to analyse `(38.73, 38.83)`.\n",
    "\n",
    "* `longitude`: The longitude range to analyse `(-122.27, -122.17)`.\n",
    "\n",
    "* `time_range`: The date range to analyse `('2018, 6, 1', '2018, 10, 1')`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the analysis parameters\n",
    "platform = 'LANDSAT_8'\n",
    "product = 'ls8_usgs_scene_digiscape'\n",
    "area = {'min_lat' : 38.73,\n",
    "        'max_lat' : 38.83,\n",
    "        'min_lon' : -122.27,\n",
    "        'max_lon' : -122.17}\n",
    "time_range =  {'start_time' : datetime.datetime(2018, 6, 1),\n",
    "               'end_time' : datetime.datetime(2018, 10, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Selected Location\n",
    "display_map(longitude=(area['min_lon'], area['max_lon']),\n",
    "            latitude=(area['min_lat'], area['max_lat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and view Landsat-8 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_chunks = {'time':1}\n",
    "\n",
    "ds = dc.load(\n",
    "     platform = platform,\n",
    "     product = product,\n",
    "     y = (area['min_lat'],\n",
    "          area['max_lat']),\n",
    "     x = (area['min_lon'], \n",
    "          area['max_lon']),\n",
    "     crs = 'epsg:4326', # Query coordinate reference system\n",
    "     output_crs = 'epsg:3488',\n",
    "     resolution = (-30, 30),\n",
    "     time = (time_range['start_time'],\n",
    "             time_range['end_time']),\n",
    "     dask_chunks = dask_chunks,\n",
    "     measurements = ['sr_red', 'sr_green', 'sr_blue', 'sr_nir', 'sr_swir2'],\n",
    "     group_by='solar_day')\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all nodata pixels to `NaN`:\n",
    "ds = masking.mask_invalid_data(ds)\n",
    "# Set all invalid data to `NaN` - valid range for USRS SR is 0 to 10000, but the surface reflectance product can have values just outside this range\n",
    "# We remove them so the image drawn isn't impacted by them\n",
    "ds = ds.where((ds >= 0) & (ds<=10000))\n",
    "\n",
    "# Select a time slice from the EO data and combine the bands into a 3 band array\n",
    "image_array = ds[['sr_red', 'sr_green', 'sr_blue']].isel(time=4).compute().to_array()\n",
    "# Show the image\n",
    "image_array.plot.imshow(robust=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Wildfires - **NBR**\n",
    "\n",
    "The Normalized burn ratio (NBR) is used to identify burned areas. This index uses the ratio of the near-infrared (NIR) and shortwave-infrared (SWIR) bands to detect burned areas. The formula is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{NBR} = \\frac{\\text{NIR} - \\text{SWIR}}{\\text{NIR} + \\text{SWIR}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Pre-fire, healthy vegetation has very high near-infrared reflectance and low reflectance in the shortwave infrared portion of the spectrum. Recently burned areas on the other hand have relatively low reflectance in the near-infrared and high reflectance in the shortwave infrared band. A high NBR value generally indicates healthy vegetation while a low value indicates bare ground and recently burned areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example - [**County Fire**](https://en.wikipedia.org/wiki/County_Fire) (June 30, 2018 â€“ July 17, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(selected_range, prod_range):\n",
    "    if (selected_range[0] < prod_range[0]) and (selected_range[1] > prod_range[0]):\n",
    "        min_range, max_range = prod_range[0], min(selected_range[1], prod_range[1])\n",
    "        \n",
    "    elif (selected_range[0] < prod_range[1]) and (selected_range[1] > prod_range[1]):\n",
    "        min_range, max_range = max(selected_range[0], prod_range[0]), prod_range[1]\n",
    "        \n",
    "    elif (selected_range[0] > prod_range[0]) and (selected_range[1] < prod_range[1]):\n",
    "        min_range, max_range = selected_range[0], selected_range[1]\n",
    "        \n",
    "    else:\n",
    "        min_range, max_range = None, None\n",
    "        \n",
    "    return min_range, max_range\n",
    "\n",
    "# Store initial values\n",
    "prev_value_dict = {'plat' : 'LANDSAT_8',\n",
    "                   'prod' : 'ls8_usgs_scene_digiscape',\n",
    "                   'lat_range' : (38.73, 38.83),\n",
    "                   'lon_range' : (-122.27, -122.17),\n",
    "                   'time_extent' : (datetime.datetime(2018, 6, 1), datetime.datetime(2018, 10, 1)),\n",
    "                   'analysis_date' : {'01 Jun 2018': datetime.datetime(2018, 6, 1, 18, 44, 28, 33152)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = dc_api.DataAccessApi()\n",
    "dc = api.dc\n",
    "products_info = dc.list_products()\n",
    "\n",
    "# Select Widgets\n",
    "plat_widget = pn.widgets.Select(name='Platform', options=['LANDSAT_8'], value='LANDSAT_8')\n",
    "prod_widget = pn.widgets.Select(name='Product', options=['ls8_usgs_scene_digiscape'])\n",
    "\n",
    "full_lat, full_lon, min_max_dates = get_overlapping_area(api, [plat_widget.value], [prod_widget.value])\n",
    "\n",
    "# Slider Widgets \n",
    "lat_widget = pn.widgets.RangeSlider(name='Latitude Range', start=full_lat[0],\n",
    "                                    end=full_lat[1], value=prev_value_dict['lat_range'], step=0.01)\n",
    "lon_widget = pn.widgets.RangeSlider(name='Longitude Range', start=full_lon[0],\n",
    "                                    end=full_lon[1], value=prev_value_dict['lon_range'], step=0.01)\n",
    "\n",
    "# Time Extent Selection Widget\n",
    "date_range_slider = pn.widgets.DateRangeSlider(name='Date Range',\n",
    "                                               start=min_max_dates[0][0], end=min_max_dates[0][1],\n",
    "                                               value=prev_value_dict['time_extent'])\n",
    "\n",
    "# Text Widget\n",
    "lat_text_default = str(prev_value_dict['lat_range'][0]) + ' | ' + str(prev_value_dict['lat_range'][1])\n",
    "lon_text_default = str(prev_value_dict['lon_range'][0]) + ' | ' + str(prev_value_dict['lon_range'][1])\n",
    "\n",
    "lat_text = pn.widgets.TextInput(name='Latitude Range ( Min_lat | Max_lat )', value=lat_text_default)\n",
    "lon_text = pn.widgets.TextInput(name='Longitude Range ( Min_lon | Max_lon )', value=lon_text_default)\n",
    "\n",
    "# Static Text Widget\n",
    "static_text = pn.widgets.StaticText(value='')\n",
    "\n",
    "@pn.depends(plat_widget.param.value, prod_widget.param.value, lat_widget.param.value, \n",
    "            lon_widget.param.value, lat_text.param.value, lon_text.param.value,\n",
    "            date_range_slider.param.value, watch=True)\n",
    "def update_widget(platform, product, lat, lon, lat_txt, lon_txt, date_range):\n",
    "    \n",
    "    # Update product widget\n",
    "    global lat_intersection, lon_intersection\n",
    "    prod_list = list(products_info[products_info['platform'] == platform]['name'])\n",
    "    prod_widget.options = prod_list\n",
    "    \n",
    "    if product not in prod_list:\n",
    "        product = prod_list[0]\n",
    "        \n",
    "    prev_value_dict['time_extent'] = date_range\n",
    "    \n",
    "    # Update lat and lon widget\n",
    "    try:\n",
    "        lat_tup = tuple([float(val) for val in lat_txt.split(' | ')])\n",
    "        lon_tup = tuple([float(val) for val in lon_txt.split(' | ')])\n",
    "        assert (len(lat_tup), len(lon_tup)) == (2,2)\n",
    "    except:\n",
    "        lat_text.value = str(round(lat[0],2)) + ' | ' + str(round(lat[1],2))\n",
    "        lon_text.value = str(round(lon[0],2)) + ' | ' + str(round(lon[1],2))\n",
    "    \n",
    "    if (len(lat_tup), len(lon_tup))  == (2,2):\n",
    "        if (lat == prev_value_dict['lat_range']) and (lat_tup != prev_value_dict['lat_range']):\n",
    "            prev_value_dict['lat_range'] = lat_tup\n",
    "            lat_widget.value = prev_value_dict['lat_range']\n",
    "\n",
    "        elif (lat != prev_value_dict['lat_range']) and (lat_tup == prev_value_dict['lat_range']):\n",
    "            prev_value_dict['lat_range'] = lat\n",
    "            lat_text.value = str(round(lat[0],2)) + ' | ' + str(round(lat[1],2))\n",
    "\n",
    "        else:\n",
    "            None\n",
    "\n",
    "        if (lon == prev_value_dict['lon_range']) and (lon_tup != prev_value_dict['lon_range']):\n",
    "            prev_value_dict['lon_range'] = lon_tup\n",
    "            lon_widget.value = prev_value_dict['lon_range']\n",
    "\n",
    "        elif (lon != prev_value_dict['lon_range']) and (lon_tup == prev_value_dict['lon_range']):\n",
    "            prev_value_dict['lon_range'] = lon\n",
    "            lon_text.value = str(round(lon[0],2)) + ' | ' + str(round(lon[1],2))\n",
    "\n",
    "        else:\n",
    "            None\n",
    "    \n",
    "    # Update lat, lon, date widget value when the product has no data\n",
    "    if (platform != prev_value_dict['plat']) or (product != prev_value_dict['prod']):\n",
    "        \n",
    "        prev_value_dict['plat'] = platform\n",
    "        prev_value_dict['prod'] = product\n",
    "        full_lat, full_lon, min_max_dates = get_overlapping_area(api, [platform], [product])\n",
    "        \n",
    "        if list(min_max_dates[0]) != [None, None]:\n",
    "            lat_widget.start, lat_widget.end, lat_widget.value = full_lat[0], full_lat[1], (prev_value_dict['lat_range'][0],\n",
    "                                                                                            prev_value_dict['lat_range'][1])\n",
    "            lon_widget.start, lon_widget.end, lon_widget.value = full_lon[0], full_lon[1], (prev_value_dict['lon_range'][0],\n",
    "                                                                                            prev_value_dict['lon_range'][1])\n",
    "            date_range_slider.start, date_range_slider.end, date_range_slider.value = min_max_dates[0][0], min_max_dates[0][1],\\\n",
    "                                                                                      (prev_value_dict['time_extent'][0],\n",
    "                                                                                       prev_value_dict['time_extent'][1])\n",
    "            static_text.value = \"\"\n",
    "        \n",
    "        else:          \n",
    "            static_text.value = \"No Data Found for \" + product\n",
    "            \n",
    "    # Check the intersection of selected lat and lon extents with the products extent\n",
    "    try:\n",
    "        full_lat, full_lon, min_max_dates = get_overlapping_area(api, [platform], [product])\n",
    "        lat_intersection, lon_intersection = intersection(lat, full_lat), intersection(lon, full_lon)\n",
    "        \n",
    "        if (lat_intersection == (None, None)) or (lon_intersection == (None, None)):\n",
    "            if list(min_max_dates[0]) != [None, None]:\n",
    "                full_lat, full_lon = tuple([round(x,2) for x in full_lat]), tuple([round(x,2) for x in full_lon])\n",
    "                static_text.value = \"There is no data for the selected extents. Use latitude values in the range {}\\\n",
    "                        and longitude values in the range {}\".format(full_lat, full_lon)\n",
    "            \n",
    "        else:\n",
    "            lat_intersection = tuple([round(x,2) for x in lat_intersection])\n",
    "            lon_intersection = tuple([round(x,2) for x in lon_intersection])\n",
    "            full_lat, full_lon = tuple([round(x,2) for x in full_lat]), tuple([round(x,2) for x in full_lon])\n",
    "            lat, lon = tuple([round(x,2) for x in lat]), tuple([round(x,2) for x in lon])\n",
    "            \n",
    "            if (lat_intersection != lat) and (lon_intersection != lon):\n",
    "                static_text.value = \"The selected latitude and longitude extents are {} and {} but the selected product's latitude\\\n",
    "                                     and longitude extents are {} and {}, so only the latitude {} and longitude range {} will be \\\n",
    "                                     used\".format(lat, lon, full_lat, full_lon, lat_intersection, lon_intersection)\n",
    "            \n",
    "            elif lat_intersection != lat:\n",
    "                static_text.value = \"The selected latitude extents are {}, but the selected product's latitude extents are {},\\\n",
    "                                     so only the latitude range {} will be used\".format(lat, full_lat, lat_intersection)\n",
    "        \n",
    "            elif lon_intersection != lon:\n",
    "                static_text.value = \"The selected longitude extents are {}, but the selected product's longitude extents are {},\\\n",
    "                                     so only the longitude range {} will be used\".format(lon, full_lon, lon_intersection)\n",
    "            \n",
    "            else:\n",
    "                static_text.value = \"\"\n",
    "                \n",
    "    except:\n",
    "        static_text.value = \"\"\n",
    "        lat_intersection, lon_intersection = None, None\n",
    "        \n",
    "pn.Column(pn.Row(plat_widget, prod_widget),\n",
    "          pn.Row(pn.Row(pn.WidgetBox(lat_widget), pn.WidgetBox(lat_text))),\n",
    "          pn.Row(pn.Row(pn.WidgetBox(lon_widget), pn.WidgetBox(lon_text))),\n",
    "          pn.WidgetBox(date_range_slider),\n",
    "          static_text,\n",
    "          update_widget,\n",
    "          width=650, height=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_load_params = dict(platform = plat_widget.value, product = prod_widget.value, latitude = lat_intersection, longitude = lon_intersection,\n",
    "                          dask_chunks = {'time':1}, time = date_range_slider.value, measurements = ['sr_red', 'sr_green', 'sr_blue', 'sr_nir', 'sr_swir2'])\n",
    "\n",
    "def load_data():\n",
    "    # Load data using Datacube api\n",
    "    ds = dc.load(**common_load_params, group_by='solar_day')\n",
    "    \n",
    "    #Calculate NBR and add it to the loaded dataset\n",
    "    ds_NBR = (ds.sr_nir-ds.sr_swir2)/(ds.sr_nir+ds.sr_swir2)\n",
    "    return ds_NBR\n",
    "\n",
    "ds_NBR = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Slider Widget\n",
    "date_slider_widget = pn.widgets.DiscreteSlider(name = 'Date', options=prev_value_dict['analysis_date'])\n",
    "\n",
    "# Convert date format from np.datetime64 to datetime.datetime\n",
    "def date_format_convert(data_cube_time):\n",
    "    ts = (data_cube_time - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    return datetime.datetime.utcfromtimestamp(ts)\n",
    "\n",
    "@pn.depends(date_slider_widget.param.value, watch=True)\n",
    "def get_input_data(analysis_date):\n",
    "           \n",
    "    # Store the current slider value\n",
    "    prev_value_dict['analysis_date'] = {analysis_date.strftime(\"%d %b %Y\") : analysis_date}\n",
    "    \n",
    "    # Get the list of scene capture dates in the selected time period\n",
    "    time_list = [date_format_convert(x) for x in list(ds_NBR.time.values)]\n",
    "    date_slider_opt = dict(zip([x.strftime(\"%d %b %Y\") for x in time_list], time_list))\n",
    "    \n",
    "    # Update Date Slider Options if new data is being loaded\n",
    "    if date_slider_widget.options != date_slider_opt:\n",
    "        date_slider_widget.options = date_slider_opt\n",
    "    \n",
    "    try:\n",
    "        index = time_list.index(analysis_date)\n",
    "    except:\n",
    "        index = 0\n",
    "\n",
    "    # Plot NBR data  \n",
    "    nbr = ds_NBR.isel(time=index).values\n",
    "    xmin, xmax = float(ds_NBR.longitude.min().values), float(ds_NBR.longitude.max().values)\n",
    "    ymin, ymax = float(ds_NBR.latitude.min().values), float(ds_NBR.latitude.max().values)\n",
    "    \n",
    "    return hv.Image(nbr, bounds=(xmin, ymin, xmax, ymax), label=str(analysis_date.strftime(\"%d %b %Y\"))).opts(colorbar=True, width=600, height=525, \n",
    "                                                                                                              cmap='RdYlGn', clim=(-1,1))\n",
    "    \n",
    "pn.Column(pn.Row(date_slider_widget),\n",
    "          pn.Row(get_input_data),\n",
    "          width=750, height=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives access to detect the severity of fire over the **County Fire** affected region in California. Red indicates fire affected region and Green indicates healthy vegetated region. Burn severity data and maps can aid in developing emergency rehabilitation and restoration plans - post-fire. They can be used to estimate not only the soil burn severity, but the likelihood of future downstream impacts due to flooding, landslides, and soil erosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "client = None\n",
    "cluster.close()\n",
    "cluster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "1. https://www.nationalgeographic.com/environment/natural-disasters/wildfires/\n",
    "2. https://science.howstuffworks.com/nature/natural-disasters/wildfire.htm\n",
    "3. https://en.wikipedia.org/wiki/List_of_California_wildfires\n",
    "4. https://www.fig.net/resources/proceedings/fig_proceedings/fig2018/ppt/ts05f/TS05F_sabuncu_ozener_9387_ppt.pdf\n",
    "5. https://en.wikipedia.org/wiki/County_Fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
